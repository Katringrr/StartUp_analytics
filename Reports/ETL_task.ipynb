{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32682bbf-c01c-4bf5-9d71-70b3f3038454",
   "metadata": {},
   "source": [
    "# Цель работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b1c43-ee17-4428-bd7e-f2657ef694e3",
   "metadata": {},
   "source": [
    "**Цель** - реализовать ETL задачу: на выходе получить DAG в Airflow, который будет каждый день рассчитывать важные показатели за предыдущий день.\n",
    "\n",
    "**Идея** - загрузить данные с Clickhouse, разбить на интересующие нас срезы и, объединив в одну табличку, выгрузить обратно в Clickhouse.\n",
    "\n",
    "**Задачи**:\n",
    "\n",
    "1. Параллельно будем обрабатывать две таблицы. В feed_actions для каждого юзера посчитаем число просмотров и лайков контента. В message_actions для каждого юзера считаем, сколько он получает и отсылает сообщений, скольким людям он пишет, сколько людей пишут ему. Каждая выгрузка должна быть в отдельном таске.\n",
    "2. Далее объединяем две таблицы в одну.\n",
    "3. Для этой таблицы считаем все эти метрики в разрезе по полу, возрасту и ос. Делаем три разных таска на каждый срез.\n",
    "4. И финальные данные со всеми метриками записываем в отдельную таблицу в ClickHouse.\n",
    "5. Каждый день таблица должна дополняться новыми данными.\n",
    "\n",
    "*Сам скрипт DAGа в конце*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449e71f7-93a7-447d-9aac-713253fafe34",
   "metadata": {},
   "source": [
    "# ETL-задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472ca13-71a9-4a94-b2fb-7c3b1d334a72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Подготовка к работе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fceba793-9138-491c-a508-7b920ef82bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка библиотек\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import requests\n",
    "import pandahouse\n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "from airflow.operators.python import get_current_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e827bc93-2417-4567-a3a4-bd118d756607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем свзять с ClickHouse\n",
    "\n",
    "connection = {\n",
    "              'host': 'https://clickhouse.lab.karpov.courses',\n",
    "              'password': 'dpo_python_2020',\n",
    "              'user': 'student',\n",
    "              'database': 'simulator_20230320'\n",
    "             }\n",
    "# И для записи нашей таблицы\n",
    "connection_test = {\n",
    "                   'host': 'https://clickhouse.lab.karpov.courses',\n",
    "                   'database':'test',\n",
    "                   'user':'student-rw', \n",
    "                   'password':'656e2b0c9c'\n",
    "                  }\n",
    "\n",
    "# Дефолтные параметры, которые используются в ДАГе\n",
    "\n",
    "default_args = {\n",
    "                'owner': 'grigorash',\n",
    "                'depends_on_past': False,\n",
    "                'retries': 2,\n",
    "                'retry_delay': timedelta(minutes=5),\n",
    "                'start_date': datetime(2023, 4, 12),\n",
    "               }\n",
    "\n",
    "# Интервал запуска DAG\n",
    "schedule_interval = '0 23 * * *'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "351ea422-fed0-40d6-b797-7fcea5b89480",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Извлечение датасетов\n",
    "# Выгружаем данные из датасета feed_actions\n",
    "def extract_fa():\n",
    "    query = \"\"\"\n",
    "                SELECT\n",
    "                        DISTINCT user_id,\n",
    "                        toDate(time) as event_date,\n",
    "                        gender,\n",
    "                        age,\n",
    "                        os,\n",
    "                        SUM(action = 'view') as views,\n",
    "                        SUM(action = 'like') as likes\n",
    "                FROM simulator_20230320.feed_actions\n",
    "                WHERE toDate(time) = yesterday() --За вчерашний день--\n",
    "                GROUP BY user_id, event_date, gender, age, os\n",
    "            \"\"\"\n",
    "    df_fa = pandahouse.read_clickhouse(query, connection=connection)\n",
    "    \n",
    "    return df_fa\n",
    "\n",
    "    \n",
    "# Выгружаем данные из датасета message_actions\n",
    "def extract_ma():\n",
    "    query = \"\"\"\n",
    "                SELECT\n",
    "                        user_id,\n",
    "                        messages_received,\n",
    "                        messages_sent,\n",
    "                        users_received,\n",
    "                        users_sent\n",
    "                FROM\n",
    "                    (SELECT\n",
    "                           user_id,\n",
    "                           COUNT() as messages_sent, --Сколько смс отправил--\n",
    "                           uniqExact(reciever_id) as users_sent --Скольким людям смс отправил--\n",
    "                     FROM simulator_20230320.message_actions\n",
    "                     WHERE toDate(time) = yesterday() --За вчерашний день--\n",
    "                     GROUP BY user_id) u1\n",
    "\n",
    "                FULL OUTER JOIN \n",
    "\n",
    "                    (SELECT\n",
    "                           reciever_id,\n",
    "                           COUNT() as messages_received, --Сколько смс получил--\n",
    "                           uniqExact(user_id) as users_received --Сколько людей смс отправили--\n",
    "                     FROM simulator_20230320.message_actions\n",
    "                     WHERE toDate(time) = yesterday() --За вчерашний день--\n",
    "                     GROUP BY reciever_id) u2\n",
    "\n",
    "                ON u1.user_id = u2.reciever_id        \n",
    "            \"\"\"\n",
    "    df_ma = pandahouse.read_clickhouse(query, connection=connection)\n",
    "    return df_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fff8ed76-4de6-4c4c-9eab-9325645cf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание одного датасета\n",
    "def merge_df(df_fa, df_ma):\n",
    "\n",
    "    df_merge = df_fa.merge(df_ma, on='user_id', how='left').fillna(0)\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d05d19ef-83ea-49bb-aaa7-61fdd23b332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#№ Считаем метрики\n",
    "common_metrics = ['event_date', 'views', 'likes', 'messages_received', 'messages_sent', 'users_received', 'users_sent']\n",
    "# Считаем метрику для гендера\n",
    "def transfrom_gender(df_merge):\n",
    "    metric_list = common_metrics + ['gender']\n",
    "    df_merge_gender = df_merge[metric_list]\\\n",
    "        .groupby(['event_date', 'gender'])\\\n",
    "        .sum()\\\n",
    "        .reset_index()\n",
    "    df_merge_gender['dimension'] = df_merge_gender.columns[1]\n",
    "    df_merge_gender.rename(columns = {'gender': 'dimension_value'}, inplace = True )\n",
    "    return df_merge_gender\n",
    "    \n",
    "# Считаем метрику для возраста\n",
    "def transfrom_age(df_merge):\n",
    "    metric_list = common_metrics + ['age']\n",
    "    df_merge_age = df_merge[metric_list]\\\n",
    "        .groupby(['event_date', 'age'])\\\n",
    "        .sum()\\\n",
    "        .reset_index()\n",
    "    df_merge_age['dimension'] = df_merge_age.columns[1]\n",
    "    df_merge_age.rename(columns = {'age': 'dimension_value'}, inplace = True )\n",
    "    return df_merge_age\n",
    "    \n",
    "# Считаем метрику для операционной системы\n",
    "def transfrom_os(df_merge):\n",
    "    metric_list = common_metrics + ['os']\n",
    "    df_merge_os = df_merge[metric_list]\\\n",
    "        .groupby(['event_date', 'os'])\\\n",
    "        .sum()\\\n",
    "        .reset_index()\n",
    "    df_merge_os['dimension'] = df_merge_os.columns[1]\n",
    "    df_merge_os.rename(columns = {'os': 'dimension_value'}, inplace = True )\n",
    "    return df_merge_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac988058-1bc1-482b-b97b-088c2da625a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем все в табличку\n",
    "def final_df(df_os, df_gender, df_age):\n",
    "    df_fin = pd.concat([df_os, df_gender, df_age])\n",
    "    df_fin = df_fin[['event_date','dimension', 'dimension_value', 'views', 'likes', \n",
    "                     'messages_received', 'messages_sent', 'users_received', 'users_sent']]\n",
    "    # Преобразуем float в int\n",
    "    df_fin = df_fin.astype({'event_date': 'str',\n",
    "                            'views': 'int64', \n",
    "                            'likes': 'int64',\n",
    "                            'messages_received': 'int64', \n",
    "                            'messages_sent': 'int64',\n",
    "                            'users_received': 'int64',\n",
    "                            'users_sent': 'int64'})\n",
    "    return df_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "574a2897-1995-4ea1-9943-81541669c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выгружаем все в Clickhouse (не работает на python - в airflow сработает)\n",
    "def load(df_fin):\n",
    "        context = get_current_context()\n",
    "        ds = context ['ds']\n",
    "        q = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS test.e_grigorash (\n",
    "            event_date String, \n",
    "            dimension String, \n",
    "            dimension_value String, \n",
    "            views Int64, \n",
    "            likes Int64, \n",
    "            messages_received Int64,\n",
    "            messages_sent Int64, \n",
    "            users_received Int64, \n",
    "            users_sent Int64                    \n",
    "            )\n",
    "            engine = MergeTree()\n",
    "            order by event_date\n",
    "            \"\"\"\n",
    "        \n",
    "        pandahouse.execute(query=q, connection=connection_test)\n",
    "        pandahouse.to_clickhouse(df=df_fin, table='e_grigorash', connection=connection_test, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1cd07a9-1c5d-48f6-ab15-78631eb610b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Все считаем\n",
    "# Таблицы\n",
    "df_fa = extract_fa()\n",
    "df_ma = extract_ma()\n",
    "df_merge = merge_df(df_fa, df_ma)\n",
    "# Метрики\n",
    "df_gender = transfrom_gender(df_merge)\n",
    "df_age = transfrom_age(df_merge)\n",
    "df_os = transfrom_os(df_merge)\n",
    "# Объединяем и выводим\n",
    "df_fin = final_df(df_os, df_gender, df_age)\n",
    "#load(df_fin) - когда уже будем загружать в Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ef065-a5df-45a0-8232-0d64a16bb8ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Код для DAG"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a6de9b9-3567-4c74-ba20-754702e50efc",
   "metadata": {},
   "source": [
    "# Установка библиотек\n",
    "\n",
    "# coding=utf-8\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import requests\n",
    "import pandahouse\n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "from airflow.operators.python import get_current_context\n",
    "\n",
    "\n",
    "# Устанавливаем свзять с ClickHouse\n",
    "\n",
    "connection = {\n",
    "    'host': 'https://clickhouse.lab.karpov.courses',\n",
    "    'password': 'dpo_python_2020',\n",
    "    'user': 'student',\n",
    "    'database': 'simulator_20230320'\n",
    "}\n",
    "# И для записи нашей таблицы\n",
    "connection_test = {\n",
    "            'host': 'https://clickhouse.lab.karpov.courses',\n",
    "            'database':'test',\n",
    "            'user':'student-rw', \n",
    "            'password':'656e2b0c9c'\n",
    "            }\n",
    "\n",
    "# Дефолтные параметры, которые используются дальше\n",
    "\n",
    "common_metrics = ['event_date', 'views', 'likes', 'messages_received', 'messages_sent', 'users_received', 'users_sent']\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'grigorash',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'start_date': datetime(2023, 4, 12),\n",
    "}\n",
    "\n",
    "# Интервал запуска DAG\n",
    "\n",
    "schedule_interval = '0 23 * * *'\n",
    "\n",
    "# Создаем ДАГ\n",
    "\n",
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup=False)\n",
    "def dag_common_metrics():\n",
    "\n",
    "    @task()\n",
    "    # выгружаем данные из датасета feed_actions\n",
    "    def extract_fa():\n",
    "        query = \"\"\"\n",
    "                SELECT\n",
    "                        DISTINCT user_id,\n",
    "                        toDate(time) as event_date,\n",
    "                        gender,\n",
    "                        age,\n",
    "                        os,\n",
    "                        SUM(action = 'view') as views,\n",
    "                        SUM(action = 'like') as likes\n",
    "                FROM simulator_20230320.feed_actions\n",
    "                WHERE toDate(time) = yesterday() --За вчерашний день--\n",
    "                GROUP BY user_id, event_date, gender, age, os\n",
    "                \"\"\"\n",
    "        df_fa = pandahouse.read_clickhouse(query, connection=connection)\n",
    "        return df_fa\n",
    "\n",
    "    \n",
    "    # выгружаем данные из датасета message_actions\n",
    "    @task()\n",
    "    def extract_ma():\n",
    "        query = \"\"\"\n",
    "                        SELECT\n",
    "                                user_id,\n",
    "                                messages_received,\n",
    "                                messages_sent,\n",
    "                                users_received,\n",
    "                                users_sent\n",
    "                        FROM\n",
    "\n",
    "                            (SELECT    \n",
    "                                  *\n",
    "                            FROM    \n",
    "                                (SELECT\n",
    "                                        user_id,\n",
    "                                        COUNT(user_id) as messages_sent --Сколько смс отправил--\n",
    "                                FROM simulator_20230320.message_actions\n",
    "                                WHERE toDate(time) = yesterday() --За вчерашний день--\n",
    "                                GROUP BY user_id) u1\n",
    "\n",
    "                                JOIN \n",
    "\n",
    "                                (SELECT\n",
    "                                        user_id,\n",
    "                                        COUNT(DISTINCT reciever_id) as users_sent --Скольким людям смс отправил--\n",
    "                                FROM simulator_20230320.message_actions\n",
    "                                WHERE toDate(time) = yesterday() --За вчерашний день--\n",
    "                                GROUP BY user_id) u2\n",
    "\n",
    "                                USING user_id) t1\n",
    "\n",
    "                        JOIN \n",
    "\n",
    "                            (SELECT    \n",
    "                                  *\n",
    "                            FROM    \n",
    "                                (SELECT\n",
    "                                        reciever_id,\n",
    "                                        COUNT(user_id) as messages_received --Сколько смс получил--\n",
    "                                FROM simulator_20230320.message_actions\n",
    "                                WHERE toDate(time) = yesterday() --За вчерашний день--\n",
    "                                GROUP BY reciever_id) r1\n",
    "\n",
    "                                JOIN \n",
    "\n",
    "                                (SELECT\n",
    "                                        reciever_id,\n",
    "                                        COUNT(DISTINCT user_id) as users_received --Сколько людей смс отправили--\n",
    "                                FROM simulator_20230320.message_actions\n",
    "                                WHERE toDate(time) = yesterday() --За вчерашний день--\n",
    "                                GROUP BY reciever_id) r2\n",
    "\n",
    "                                USING reciever_id) t2\n",
    "\n",
    "                        ON t1.user_id = t2.reciever_id        \n",
    "                        \"\"\"\n",
    "        df_ma = pandahouse.read_clickhouse(query, connection=connection)\n",
    "        return df_ma\n",
    "    \n",
    "    # Создание одного датасета\n",
    "    @task()\n",
    "    def merge_df(df_fa, df_ma):\n",
    "\n",
    "        df_merge = df_fa.merge(df_ma, on='user_id', how='left').fillna(0)\n",
    "        return df_merge\n",
    "    \n",
    "    # Считаем метрику для гендера\n",
    "    @task()\n",
    "    def transfrom_gender(df_merge):\n",
    "        metric_list = common_metrics + ['gender']\n",
    "        df_merge_gender = df_merge[metric_list]\\\n",
    "            .groupby(['event_date', 'gender'])\\\n",
    "            .sum()\\\n",
    "            .reset_index()\n",
    "        df_merge_gender['dimension'] = df_merge_gender.columns[1]\n",
    "        df_merge_gender.rename(columns = {'gender': 'dimension_value'}, inplace = True )\n",
    "        return df_merge_gender\n",
    "    \n",
    "    # Считаем метрику для возраста\n",
    "    @task()\n",
    "    def transfrom_age(df_merge):\n",
    "        metric_list = common_metrics + ['age']\n",
    "        df_merge_age = df_merge[metric_list]\\\n",
    "            .groupby(['event_date', 'age'])\\\n",
    "            .sum()\\\n",
    "            .reset_index()\n",
    "        df_merge_age['dimension'] = df_merge_age.columns[1]\n",
    "        df_merge_age.rename(columns = {'age': 'dimension_value'}, inplace = True )\n",
    "        return df_merge_age\n",
    "    \n",
    "    # Считаем метрику для операционной системы\n",
    "    @task()\n",
    "    def transfrom_os(df_merge):\n",
    "        metric_list = common_metrics + ['os']\n",
    "        df_merge_os = df_merge[metric_list]\\\n",
    "            .groupby(['event_date', 'os'])\\\n",
    "            .sum()\\\n",
    "            .reset_index()\n",
    "        df_merge_os['dimension'] = df_merge_os.columns[1]\n",
    "        df_merge_os.rename(columns = {'os': 'dimension_value'}, inplace = True )\n",
    "        return df_merge_os\n",
    "    \n",
    "    # Объединяем все метрики в одну таблицу\n",
    "    @task()\n",
    "    def final_df(df_os, df_gender, df_age):\n",
    "        df_fin = pd.concat([df_os, df_gender, df_age])\n",
    "        df_fin = df_fin[['event_date','dimension', 'dimension_value', 'views', 'likes', \n",
    "                         'messages_received', 'messages_sent', 'users_received', 'users_sent']]\n",
    "        # Преобразуем float в int\n",
    "        df_fin = df_fin.astype({'event_date': 'str',\n",
    "                                'views': 'int64', \n",
    "                                'likes': 'int64',\n",
    "                                'messages_received': 'int64', \n",
    "                                'messages_sent': 'int64',\n",
    "                                'users_received': 'int64',\n",
    "                                'users_sent': 'int64'})\n",
    "        return df_fin\n",
    "    \n",
    "    # Загружаем в ClickHouse\n",
    "    @task()\n",
    "    def load(df_fin):\n",
    "        context = get_current_context()\n",
    "        ds = context ['ds']\n",
    "        q = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS test.e_grigorash (\n",
    "            event_date String, \n",
    "            dimension String, \n",
    "            dimension_value String, \n",
    "            views Int64, \n",
    "            likes Int64, \n",
    "            messages_received Int64,\n",
    "            messages_sent Int64, \n",
    "            users_received Int64, \n",
    "            users_sent Int64                    \n",
    "            )\n",
    "            engine = MergeTree()\n",
    "            order by event_date\n",
    "            \"\"\"\n",
    "        \n",
    "        pandahouse.execute(query=q, connection=connection_test)\n",
    "        pandahouse.to_clickhouse(df=df_fin, table='e_grigorash', connection=connection_test, index=False)\n",
    "        \n",
    "    ## Все считаем\n",
    "    \n",
    "    # Таблицы\n",
    "    df_fa = extract_fa()\n",
    "    df_ma = extract_ma()\n",
    "    df_merge = merge_df(df_fa, df_ma)\n",
    "    # Метрики\n",
    "    df_gender = transfrom_gender(df_merge)\n",
    "    df_age = transfrom_age(df_merge)\n",
    "    df_os = transfrom_os(df_merge)\n",
    "    # Объединяем и выводим\n",
    "    df_fin = final_df(df_os, df_gender, df_age)\n",
    "    load(df_fin)\n",
    "\n",
    "\n",
    "dag_common_metrics = dag_common_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
